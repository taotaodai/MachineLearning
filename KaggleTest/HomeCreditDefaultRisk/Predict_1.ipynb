{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,Imputer, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要数据\n",
    "df_train_origin = pd.read_csv('data/application_train.csv')\n",
    "df_test_origin = pd.read_csv('data/application_test.csv')\n",
    "\n",
    "combine_origin = [df_train_origin,df_test_origin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信用局中以前信用的每月余额。\n",
    "# 该表在向信用局报告的每个先前信用的历史记录的每个月中都有一行–即该表具有（样本中的＃贷款*相对先前信用的数量*我们可以观察到先前信用的历史的月份数）行。\n",
    "df_bureau_balance = pd.read_csv('data/bureau_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau_balance_num = df_bureau_balance.select_dtypes('number')\n",
    "df_bureau_balance_num = df_bureau_balance_num.groupby('SK_ID_BUREAU').agg(['min','max','sum','mean'])\n",
    "df_bureau_balance_cate = df_bureau_balance.select_dtypes('object')\n",
    "df_bureau_balance_cate = pd.get_dummies(df_bureau_balance_cate)\n",
    "df_bureau_balance_cate.loc[:,'SK_ID_BUREAU'] = df_bureau_balance['SK_ID_BUREAU']\n",
    "df_bureau_balance_cate = df_bureau_balance_cate.groupby('SK_ID_BUREAU').agg(['sum','mean'])\n",
    "\n",
    "df_bureau_balance_bybuerauid = df_bureau_balance_num.merge(df_bureau_balance_cate,on='SK_ID_BUREAU',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817395, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bureau_balance_bybuerauid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由其他金融机构提供给客户的所有以前的信贷，这些信贷已报告给信贷局（针对在我们的样本中有贷款的客户）。\n",
    "# 对于我们样本中的每笔贷款，行数与客户在申请日期之前在信用局中拥有的信用数一样多。\n",
    "df_bureau = pd.read_csv('data/bureau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau = df_bureau.merge(df_bureau_balance_bybuerauid,on='SK_ID_BUREAU',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau_num = df_bureau.select_dtypes('number')\n",
    "\n",
    "df_bureau_num.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "df_bureau_num.loc[:,'AMT_CREDIT_MAX_OVERDUE'] = df_bureau_num['AMT_CREDIT_MAX_OVERDUE'].apply(lambda x:round(x / 10000,2))\n",
    "df_bureau_num.loc[:,'AMT_CREDIT_SUM'] = df_bureau_num['AMT_CREDIT_SUM'].apply(lambda x:round(x / 10000,2))\n",
    "df_bureau_num.loc[:,'AMT_CREDIT_SUM_DEBT'] = df_bureau_num['AMT_CREDIT_SUM_DEBT'].apply(lambda x:round(x / 10000,2))\n",
    "df_bureau_num.loc[:,'AMT_CREDIT_SUM_LIMIT'] = df_bureau_num['AMT_CREDIT_SUM_LIMIT'].apply(lambda x:round(x / 10000,2))\n",
    "df_bureau_num.loc[:,'AMT_CREDIT_SUM_OVERDUE'] = df_bureau_num['AMT_CREDIT_SUM_OVERDUE'].apply(lambda x:round(x / 10000,2))\n",
    "df_bureau_num.loc[:,'AMT_ANNUITY'] = df_bureau_num['AMT_ANNUITY'].apply(lambda x:round(x / 10000,2))\n",
    "\n",
    "df_bureau_num = df_bureau_num.drop(['SK_ID_BUREAU'],axis=1)\n",
    "\n",
    "df_bureau_num = df_bureau_num.groupby('SK_ID_CURR').agg(['min','max','sum','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau_cate = df_bureau.select_dtypes('object')\n",
    "df_bureau_cate = pd.get_dummies(df_bureau_cate)\n",
    "df_bureau_cate.loc[:,'SK_ID_CURR'] = df_bureau['SK_ID_CURR']\n",
    "df_bureau_cate = df_bureau_cate.groupby('SK_ID_CURR').agg(['sum','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau_bycurrid = df_bureau_num.merge(df_bureau_cate,on='SK_ID_CURR',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305811, 174)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bureau_bycurrid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 申请人通过房屋信贷拥有的先前信用卡的月度余额快照。\n",
    "# 该表格在与样本中的贷款相关的房屋信贷（消费者信贷和现金贷款）中的每个先前信用的历史记录的每个月都有一行-即该表具有（（样本中的贷款*相对以前的信用卡数量*的＃个）以前的信用卡行中有一些历史记录的月份。\n",
    "df_credit_card_balance = pd.read_csv('data/credit_card_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 申请人通过房屋信贷拥有的先前POS（销售点）和现金贷款的每月余额快照。\n",
    "# 该表在与样本中的贷款相关的房屋信贷（消费者信贷和现金贷款）中的每个先前信贷的历史记录的每个月中都有一行-即该表具有（（样本中的贷款*相对先前信贷的数量*月数）在其中，我们有一些历史记录可用于查看以前的信用记录。\n",
    "df_POS_CASH_balance = pd.read_csv('data/POS_CASH_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在我们的样本中有贷款的客户以前所有的房屋信贷申请。\n",
    "# 在我们的数据样本中，每个与贷款相关的先前申请都有一行。\n",
    "df_previous_application = pd.read_csv('data/previous_application.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与我们样本中的贷款相关的房屋信贷中先前已支付的信贷的还款历史。\n",
    "# 有a）每笔付款都有一行，另加b）每笔未付款都有一行。\n",
    "# 一行等于我们分期付款中一笔还清一笔贷款，或者相当于一笔分期付款，相当于一笔以前一笔与贷款相关的房屋信用信贷的付款。\n",
    "df_installments_payments = pd.read_csv('data/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[[\"FLAG_OWN_CAR\", \"TARGET\"]].groupby(['FLAG_OWN_CAR'], as_index=False).mean().sort_values(by='TARGET', ascending=False)\n",
    "\n",
    "# 收教育程度高低和逾期存在关系\n",
    "# df_train_origin[[\"NAME_EDUCATION_TYPE\", \"TARGET\"]].groupby(['NAME_EDUCATION_TYPE'], as_index=False).mean().sort_values(by='TARGET', ascending=False)\n",
    "\n",
    "# 通过箱型图观察，每期还款金额会影响逾期\n",
    "# df_train_origin[df_train_origin['TARGET'] == 1][['AMT_ANNUITY']].plot.box()\n",
    "# df_train_origin[df_train_origin['TARGET'] == 0][['AMT_ANNUITY']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理。空值、异常数据、对number/object数据编码、特征工程\n",
    "combine = []\n",
    "le = preprocessing.LabelEncoder()\n",
    "# ohe = preprocessing.OneHotEncoder(categories='auto')\n",
    "for i,dataset in enumerate(combine_origin):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    try:\n",
    "        df = dataset[['SK_ID_CURR','TARGET']]\n",
    "    except:\n",
    "        df = dataset[['SK_ID_CURR']]\n",
    "\n",
    "    dataset.replace(np.nan, 0, inplace=True)\n",
    "    dataset.replace(np.inf, 0, inplace=True)\n",
    "    \n",
    "    dataset['AMT_INCOME_TOTAL'] = dataset['AMT_INCOME_TOTAL'].apply(lambda x:round(x / 10000,2))\n",
    "    dataset['AMT_CREDIT'] = dataset['AMT_CREDIT'].apply(lambda x:round(x / 10000,2))\n",
    "    dataset['AMT_ANNUITY'] = dataset['AMT_ANNUITY'].apply(lambda x:round(x / 10000,2))\n",
    "    dataset['AMT_GOODS_PRICE'] = dataset['AMT_GOODS_PRICE'].apply(lambda x:round(x / 10000,2))\n",
    "    \n",
    "    dataset['REGION_POPULATION_RELATIVE'] = dataset['REGION_POPULATION_RELATIVE'].apply(lambda x:round(x,3))\n",
    "    dataset['EXT_SOURCE_1'] = dataset['EXT_SOURCE_1'].apply(lambda x:round(x,3))\n",
    "    dataset['EXT_SOURCE_2'] = dataset['EXT_SOURCE_2'].apply(lambda x:round(x,3))\n",
    "    dataset['EXT_SOURCE_3'] = dataset['EXT_SOURCE_3'].apply(lambda x:round(x,3))\n",
    "    \n",
    "    # 处理天数。\n",
    "    dataset['DAYS_BIRTH'] = dataset['DAYS_BIRTH'].apply(lambda x:round(x/-365,1))\n",
    "    dataset['DAYS_EMPLOYED'] = dataset['DAYS_EMPLOYED'].apply(lambda x:round(x/-365,1))\n",
    "    #处理异常的天数\n",
    "    dataset.loc[dataset['DAYS_EMPLOYED'] < 0,'DAYS_EMPLOYED'] = dataset[dataset['DAYS_EMPLOYED'] > 0]['DAYS_EMPLOYED'].mean()\n",
    "    \n",
    "    dataset['DAYS_REGISTRATION'] = dataset['DAYS_REGISTRATION'].apply(lambda x:round(x/-365,1))\n",
    "    dataset['DAYS_ID_PUBLISH'] = dataset['DAYS_ID_PUBLISH'].apply(lambda x:round(x/-365,1))\n",
    "    dataset['DAYS_LAST_PHONE_CHANGE'] = dataset['DAYS_LAST_PHONE_CHANGE'].apply(lambda x:round(x/-365,1))\n",
    "    \n",
    "    # 二分类数据用LabelEncoder进行编码\n",
    "    dataset['NAME_CONTRACT_TYPE'] = le.fit_transform(dataset['NAME_CONTRACT_TYPE'])\n",
    "#     dataset['NAME_CONTRACT_TYPE'] = dataset['NAME_CONTRACT_TYPE'].map({\"Cash loans\":1,\"Revolving loans\":2})\n",
    "    \n",
    "    dataset['FLAG_OWN_CAR'] = le.fit_transform(dataset['FLAG_OWN_CAR'])\n",
    "#     dataset['FLAG_OWN_CAR'] = dataset['FLAG_OWN_CAR'].map({\"N\":0,\"Y\":1})\n",
    "    dataset['FLAG_OWN_REALTY'] = le.transform(dataset['FLAG_OWN_REALTY'])\n",
    "#     dataset['FLAG_OWN_REALTY'] = dataset['FLAG_OWN_REALTY'].map({\"N\":0,\"Y\":1})\n",
    "    \n",
    "#     dataset['CODE_GENDER'] = dataset['CODE_GENDER'].map({\"F\":1,\"M\":2,\"XNA\":3})\n",
    "    \n",
    "#     dataset['NAME_TYPE_SUITE'] = le.fit_transform(dataset['NAME_TYPE_SUITE'])\n",
    "#     dataset['NAME_TYPE_SUITE'] = dataset['NAME_TYPE_SUITE'].map({\"Unaccompanied\":1,\"Family\":2,\"Spouse, partner\":3,\"Children\":4,\"Other_B\":5,\"Other_A\":6,\"Group of people\":7})\n",
    "#     dataset['NAME_TYPE_SUITE'] = dataset['NAME_TYPE_SUITE'].fillna(0)\n",
    "\n",
    "#     dataset['NAME_INCOME_TYPE'] = le.fit_transform(dataset['NAME_INCOME_TYPE'])\n",
    "#     dataset['NAME_INCOME_TYPE'] = dataset['NAME_INCOME_TYPE'].map({\"Working\":1,\"Commercial associate\":2,\"Pensioner\":3,\"State servant\":4,\"Unemployed\":5,\"Student\":6,\"Businessman\":7,\"Maternity leave\":8})\n",
    "\n",
    "#     dataset['NAME_FAMILY_STATUS'] = le.fit_transform(dataset['NAME_FAMILY_STATUS'])\n",
    "#     dataset['NAME_FAMILY_STATUS'] = dataset['NAME_FAMILY_STATUS'].map({\"Married\":1,\"Single / not married\":2,\"Civil marriage\":3,\"Separated\":4,\"Widow\":5,\"Unknown\":6})\n",
    "\n",
    "#     dataset['NAME_HOUSING_TYPE'] = le.fit_transform(dataset['NAME_HOUSING_TYPE'])\n",
    "#     dataset['NAME_HOUSING_TYPE'] = dataset['NAME_HOUSING_TYPE'].map({\"House / apartment\":1,\"With parents\":2,\"Municipal apartment\":3,\"Rented apartment\":4,\"Office apartment\":5,\"Co-op apartment\":6})\n",
    "    \n",
    "#     dataset['WEEKDAY_APPR_PROCESS_START'] = dataset['WEEKDAY_APPR_PROCESS_START'].map({\"SUNDAY\":1,\"SATURDAY\":2,\"FRIDAY\":3,\"THURSDAY\":4,\"MONDAY\":5,\"WEDNESDAY\":6,\"TUESDAY\":7})\n",
    "#     dataset['NAME_EDUCATION_TYPE'] = dataset['NAME_EDUCATION_TYPE'].map({\"Lower secondary\":1,\"Secondary / secondary special\":2,\"Incomplete higher\":3,\"Higher education\":4,\"Academic degree\":5})\n",
    "    \n",
    "    for suffix in ['_AVG','_MODE','_MEDI']:\n",
    "        dataset = dataset.drop(['APARTMENTS' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['BASEMENTAREA' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['YEARS_BEGINEXPLUATATION' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['YEARS_BUILD' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['COMMONAREA' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['ELEVATORS' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['ENTRANCES' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['FLOORSMAX' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['FLOORSMIN' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['LANDAREA' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['LIVINGAPARTMENTS' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['LIVINGAREA' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['NONLIVINGAPARTMENTS' + suffix], axis=1)\n",
    "        dataset = dataset.drop(['NONLIVINGAREA' + suffix], axis=1)\n",
    "        \n",
    "    dataset = dataset.drop(['FONDKAPREMONT_MODE'], axis=1)\n",
    "    dataset = dataset.drop(['HOUSETYPE_MODE'], axis=1)\n",
    "    dataset = dataset.drop(['TOTALAREA_MODE'], axis=1)\n",
    "    dataset = dataset.drop(['WALLSMATERIAL_MODE'], axis=1)\n",
    "    dataset = dataset.drop(['EMERGENCYSTATE_MODE'], axis=1)\n",
    "    \n",
    "    #商品价格-填充空值\n",
    "    dataset.loc[dataset['AMT_GOODS_PRICE'] == 0,'AMT_GOODS_PRICE'] = dataset['AMT_GOODS_PRICE'].median()\n",
    "    #每期还款-填充空值\n",
    "    dataset.loc[dataset['AMT_ANNUITY'] == 0,'AMT_ANNUITY'] = dataset['AMT_ANNUITY'].median()\n",
    "    # 其他\n",
    "    dataset = pd.get_dummies(dataset)\n",
    "    \n",
    "    combine_origin[i] = dataset\n",
    "    \n",
    "    # 收入/信贷金额\n",
    "    dataset['RATE_INCOME_CREDIT'] = dataset['AMT_INCOME_TOTAL'] / dataset['AMT_CREDIT']\n",
    "    # 收入/商品价格\n",
    "    dataset['RATE_INCOME_GPRICE'] = dataset['AMT_INCOME_TOTAL'] / dataset['AMT_GOODS_PRICE']\n",
    "    # 每期还款/信贷金额\n",
    "    dataset['RATE_ANNUITY_CREDIT'] = dataset['AMT_ANNUITY'] / dataset['AMT_CREDIT']\n",
    "    # 每期还款/收入\n",
    "    dataset['RATE_ANNUITY_INCOME'] = dataset['AMT_ANNUITY'] / dataset['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    combine.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,dataset in enumerate(combine_origin):\n",
    "    dataset = dataset.merge(df_bureau_bycurrid,on='SK_ID_CURR',how='left')\n",
    "    \n",
    "    dataset.replace(np.nan, 0, inplace=True)\n",
    "    \n",
    "    combine_origin[i] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析相关性\n",
    "# 特性选择。方案一\n",
    "corr = combine_origin[0].corr()['TARGET'].sort_values()\n",
    "features = corr[(abs(corr) > 0.01)]\n",
    "\n",
    "# 选择特性。方案二\n",
    "# select = SelectPercentile(percentile=50)\n",
    "# select.fit(X_train, Y_train)\n",
    "\n",
    "# X_train_selected = select.transform(X_train)\n",
    "# support = select.get_support()\n",
    "\n",
    "# support_list = []\n",
    "# colunms = X_train.columns.values\n",
    "# for i,s in enumerate(support):\n",
    "#     if s:\n",
    "#         support_list.append(colunms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 364)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_origin[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,dataset in enumerate(combine_origin):\n",
    "    df = combine[i]\n",
    "    \n",
    "    df = pd.concat([df,dataset[['EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH',\n",
    "       ('CREDIT_ACTIVE_Closed', 'mean'), 'DAYS_EMPLOYED', 'EXT_SOURCE_1',\n",
    "       'NAME_EDUCATION_TYPE_Higher education', 'DAYS_LAST_PHONE_CHANGE',\n",
    "       'CODE_GENDER_F', 'DAYS_ID_PUBLISH', 'NAME_INCOME_TYPE_Pensioner',\n",
    "       'ORGANIZATION_TYPE_XNA', 'DAYS_REGISTRATION', 'AMT_GOODS_PRICE',\n",
    "       'OCCUPATION_TYPE_0', ('CREDIT_TYPE_Consumer credit', 'mean'),\n",
    "       'REGION_POPULATION_RELATIVE', ('CREDIT_ACTIVE_Closed', 'sum'),\n",
    "       'NAME_CONTRACT_TYPE', ('CREDIT_CURRENCY_currency 1', 'mean'),\n",
    "       'AMT_CREDIT', 'FLAG_DOCUMENT_6',\n",
    "       'NAME_HOUSING_TYPE_House / apartment',\n",
    "       'NAME_FAMILY_STATUS_Married', 'HOUR_APPR_PROCESS_START',\n",
    "       'FLAG_PHONE', ('CREDIT_TYPE_Mortgage', 'sum'),\n",
    "       'NAME_INCOME_TYPE_State servant', ('AMT_CREDIT_SUM', 'max'),\n",
    "       ('AMT_CREDIT_SUM', 'mean'), 'FLAG_OWN_CAR',\n",
    "       ('CREDIT_TYPE_Car loan', 'sum'), 'OCCUPATION_TYPE_Accountants',\n",
    "       ('CREDIT_TYPE_Consumer credit', 'sum'),\n",
    "       ('CREDIT_TYPE_Mortgage', 'mean'), ('CREDIT_TYPE_Car loan', 'mean'),\n",
    "       'OCCUPATION_TYPE_Core staff', 'NAME_FAMILY_STATUS_Widow',\n",
    "       'OCCUPATION_TYPE_Managers', ('AMT_CREDIT_SUM', 'sum'),\n",
    "       'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "       'OCCUPATION_TYPE_High skill tech staff',\n",
    "       'ORGANIZATION_TYPE_School', 'AMT_ANNUITY',\n",
    "       ('AMT_CREDIT_SUM_LIMIT', 'max'), ('AMT_CREDIT_SUM', 'min'),\n",
    "       ('AMT_CREDIT_SUM_LIMIT', 'mean'),\n",
    "       'NAME_INCOME_TYPE_Commercial associate', 'FLAG_DOCUMENT_16',\n",
    "       'FLAG_DOCUMENT_13', ('AMT_CREDIT_SUM_LIMIT', 'sum'),\n",
    "       'ORGANIZATION_TYPE_Medicine', 'ORGANIZATION_TYPE_Military',\n",
    "       'ORGANIZATION_TYPE_Restaurant',\n",
    "       'NAME_EDUCATION_TYPE_Lower secondary',\n",
    "       ('AMT_CREDIT_SUM_OVERDUE', 'sum'), 'OCCUPATION_TYPE_Cooking staff',\n",
    "       'RATE_ANNUITY_CREDIT', ('CREDIT_ACTIVE_Sold', 'mean'),\n",
    "       'RATE_ANNUITY_INCOME', 'OCCUPATION_TYPE_Security staff',\n",
    "       'ORGANIZATION_TYPE_Transport: type 3', 'CNT_CHILDREN',\n",
    "       ('CREDIT_TYPE_Credit card', 'mean'), 'OCCUPATION_TYPE_Sales staff',\n",
    "       'NAME_HOUSING_TYPE_Rented apartment',\n",
    "       'ORGANIZATION_TYPE_Construction',\n",
    "       ('CREDIT_TYPE_Credit card', 'sum'),\n",
    "       'NAME_FAMILY_STATUS_Civil marriage',\n",
    "       'ORGANIZATION_TYPE_Business Entity Type 3',\n",
    "       'NAME_FAMILY_STATUS_Single / not married',\n",
    "       ('DAYS_CREDIT_ENDDATE', 'max'), ('DAYS_ENDDATE_FACT', 'max'),\n",
    "       'OCCUPATION_TYPE_Low-skill Laborers', 'FLAG_WORK_PHONE',\n",
    "       'ORGANIZATION_TYPE_Self-employed',\n",
    "       'NAME_HOUSING_TYPE_With parents', ('DAYS_CREDIT_UPDATE', 'max'),\n",
    "       ('CREDIT_TYPE_Microloan', 'sum'), 'OCCUPATION_TYPE_Drivers',\n",
    "       'DEF_60_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "       'LIVE_CITY_NOT_WORK_CITY', ('DAYS_CREDIT_ENDDATE', 'min'),\n",
    "       ('DAYS_CREDIT_ENDDATE', 'mean'), ('CREDIT_TYPE_Microloan', 'mean'),\n",
    "       'OCCUPATION_TYPE_Laborers', ('CREDIT_ACTIVE_Active', 'sum'),\n",
    "       'FLAG_DOCUMENT_3', 'REG_CITY_NOT_LIVE_CITY',\n",
    "       ('DAYS_CREDIT_UPDATE', 'sum'), 'FLAG_EMP_PHONE',\n",
    "       ('DAYS_CREDIT_ENDDATE', 'sum'), ('DAYS_CREDIT', 'sum'),\n",
    "       ('DAYS_CREDIT_UPDATE', 'min'), ('CREDIT_ACTIVE_Active', 'mean'),\n",
    "       'NAME_EDUCATION_TYPE_Secondary / secondary special',\n",
    "       'REG_CITY_NOT_WORK_CITY', ('DAYS_ENDDATE_FACT', 'sum'),\n",
    "       ('DAYS_CREDIT', 'max'), 'CODE_GENDER_M',\n",
    "       'NAME_INCOME_TYPE_Working', 'REGION_RATING_CLIENT',\n",
    "       'REGION_RATING_CLIENT_W_CITY', ('DAYS_ENDDATE_FACT', 'min'),\n",
    "       ('DAYS_CREDIT_UPDATE', 'mean'), ('DAYS_CREDIT', 'min'),\n",
    "       ('DAYS_ENDDATE_FACT', 'mean'), ('DAYS_CREDIT', 'mean')]]],axis=1)\n",
    "    \n",
    "    # 多项式特征\n",
    "    features_list = ['AMT_CREDIT', 'AMT_GOODS_PRICE']\n",
    "    poly_features = dataset[features_list]\n",
    "    poly_transformer = PolynomialFeatures(degree=3)\n",
    "    poly_features = poly_transformer.fit_transform(poly_features)\n",
    "    poly_features = pd.DataFrame(poly_features, columns=poly_transformer.get_feature_names(features_list))\n",
    "    \n",
    "    df = pd.concat([df,poly_features[['AMT_GOODS_PRICE^2']]],axis=1)\n",
    "    \n",
    "    df.replace(np.nan, 0, inplace=True)\n",
    "    df.replace(np.inf, 0, inplace=True)\n",
    "    \n",
    "    combine[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_list = ['AMT_CREDIT', 'AMT_GOODS_PRICE']\n",
    "# features_list = ['REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY']\n",
    "# features_list = ['DAYS_BIRTH', 'DAYS_EMPLOYED','DAYS_LAST_PHONE_CHANGE','DAYS_REGISTRATION','DAYS_ID_PUBLISH']\n",
    "\n",
    "# poly_features = combine_origin[0][features_list]\n",
    "# poly_target = combine_origin[0]['TARGET']\n",
    "# poly_transformer = PolynomialFeatures(degree=3)\n",
    "# poly_features = poly_transformer.fit_transform(poly_features)\n",
    "# poly_features = pd.DataFrame(poly_features, columns=poly_transformer.get_feature_names(features_list))\n",
    "\n",
    "# poly_features['TARGET'] = poly_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 364)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_origin[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = combine_origin[0]\n",
    "df_test = combine_origin[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"TARGET\",'SK_ID_CURR'], axis=1)\n",
    "Y_train = df_train[\"TARGET\"]\n",
    "\n",
    "X_test  = df_test.drop(\"SK_ID_CURR\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据对齐\n",
    "X_train, X_test = X_train.align(X_test, join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 359)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征缩放\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 359)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = linear_model.LinearRegression()\n",
    "# model.fit(X_train, Y_train)\n",
    "# Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear',max_iter=10000)\n",
    "logreg.fit(X_train,Y_train)\n",
    "# Y_pred = logreg.predict(X_test)\n",
    "Y_pred = logreg.predict_proba(X_test)\n",
    "# acc_log = logreg.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n",
    "random_forest.fit(X_train,Y_train)\n",
    "Y_pred = random_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for t in Y_pred:\n",
    "    pred.append(t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c9f112c368d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "max(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"SK_ID_CURR\": df_test_origin[\"SK_ID_CURR\"],\n",
    "        \"TARGET\": pred\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('result/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
