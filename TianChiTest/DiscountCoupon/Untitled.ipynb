{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0,1,2,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0,1,2,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dataset split:\n",
    "                      (date_received)                              \n",
    "           dateset3: 20160701~20160731 (113640),features3 from 20160315~20160630  (off_test)\n",
    "           dateset2: 20160515~20160615 (258446),features2 from 20160201~20160514  \n",
    "           dateset1: 20160414~20160514 (138303),features1 from 20160101~20160413        \n",
    "1.merchant related: \n",
    "      sales_use_coupon. total_coupon\n",
    "      transfer_rate = sales_use_coupon/total_coupon.\n",
    "      merchant_avg_distance,merchant_min_distance,merchant_max_distance of those use coupon \n",
    "      total_sales.  coupon_rate = sales_use_coupon/total_sales.  \n",
    "       \n",
    "2.coupon related: \n",
    "      discount_rate. discount_man. discount_jian. is_man_jian\n",
    "      day_of_week,day_of_month. (date_received)\n",
    "      \n",
    "3.user related: \n",
    "      distance. \n",
    "      user_avg_distance, user_min_distance,user_max_distance. \n",
    "      buy_use_coupon. buy_total. coupon_received.\n",
    "      buy_use_coupon/coupon_received. \n",
    "      avg_diff_date_datereceived. min_diff_date_datereceived. max_diff_date_datereceived.  \n",
    "      count_merchant.  \n",
    "4.user_merchant:\n",
    "      times_user_buy_merchant_before.\n",
    "     \n",
    "5. other feature:\n",
    "      this_month_user_receive_all_coupon_count\n",
    "      this_month_user_receive_same_coupon_count\n",
    "      this_month_user_receive_same_coupon_lastone\n",
    "      this_month_user_receive_same_coupon_firstone\n",
    "      this_day_user_receive_all_coupon_count\n",
    "      this_day_user_receive_same_coupon_count\n",
    "      day_gap_before, day_gap_after  (receive the same coupon)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#1754884 record,1053282 with coupon_id,9738 coupon. date_received:20160101~20160615,date:20160101~20160630, 539438 users, 8415 merchants\n",
    "off_train = pd.read_csv('data/ccf_offline_stage1_train.csv',header=None)\n",
    "off_train.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']\n",
    "#2050 coupon_id. date_received:20160701~20160731, 76309 users(76307 in trainset, 35965 in online_trainset), 1559 merchants(1558 in trainset)\n",
    "off_test = pd.read_csv('data/ccf_offline_stage1_test_revised.csv',header=None)\n",
    "off_test.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received']\n",
    "#11429826 record(872357 with coupon_id),762858 user(267448 in off_train)\n",
    "on_train = pd.read_csv('data/ccf_online_stage1_train.csv',header=None)\n",
    "on_train.columns = ['user_id','merchant_id','action','coupon_id','discount_rate','date_received','date']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    20160528\n",
       "Name: date_received, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# off_train.date[1:2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset3 = off_test\n",
    "feature3 = off_train[((off_train.date.apply(lambda x:str(x)>='20160315'))&(off_train.date.apply(lambda x:str(x)<='20160630')))|\n",
    "                     ((off_train.date.isnull())&(off_train.date_received.apply(lambda x:str(x)>='20160315'))&(off_train.date_received.apply(lambda x:str(x)<='20160630')))]\n",
    "dataset2 = off_train[(off_train.date_received.apply(lambda x:str(x)>='20160515'))&(off_train.date_received.apply(lambda x:str(x)<='20160615'))]\n",
    "feature2 = off_train[(off_train.date.apply(lambda x:str(x)>='20160201'))&(off_train.date.apply(lambda x:str(x)<='20160514'))|\n",
    "                     ((off_train.date.isnull())&(off_train.date_received.apply(lambda x:str(x)>='20160201'))&(off_train.date_received.apply(lambda x:str(x)<='20160514')))]\n",
    "dataset1 = off_train[(off_train.date_received.apply(lambda x:str(x)>='20160414'))&(off_train.date_received.apply(lambda x:str(x)<='20160514'))]\n",
    "feature1 = off_train[(off_train.date.apply(lambda x:str(x)>='20160101'))&(off_train.date.apply(lambda x:str(x)<='20160413'))|\n",
    "                     ((off_train.date.isnull())&(off_train.date_received.apply(lambda x:str(x)>='20160101'))&(off_train.date_received.apply(lambda x:str(x)<='20160413')))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(802399, 7)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1012\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-f1f21876142e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mt3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'coupon_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'date_received'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mt3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'coupon_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mt3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'this_month_user_receive_same_coupon_lastone'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_date_received\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'this_month_user_receive_same_coupon_firstone'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_received\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_date_received\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_na_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m         return construct_result(left, result,\n\u001b[0;32m   1071\u001b[0m                                 index=left.index, name=res_name, dtype=None)\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[1;34m(lvalues, rvalues)\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1016\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mnotna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1019\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "############# other feature ##################3\n",
    "\"\"\"\n",
    "5. other feature:\n",
    "      this_month_user_receive_all_coupon_count\n",
    "      this_month_user_receive_same_coupon_count\n",
    "      this_month_user_receive_same_coupon_lastone\n",
    "      this_month_user_receive_same_coupon_firstone\n",
    "      this_day_user_receive_all_coupon_count\n",
    "      this_day_user_receive_same_coupon_count\n",
    "      day_gap_before, day_gap_after  (receive the same coupon)\n",
    "\"\"\"\n",
    "\n",
    "#for dataset3\n",
    "t = dataset3[['user_id']]\n",
    "t['this_month_user_receive_all_coupon_count'] = 1\n",
    "t = t.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t1 = dataset3[['user_id','coupon_id']]\n",
    "t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "t2 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t2.date_received = t2.date_received.astype('str')\n",
    "t2 = t2.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t2['receive_number'] = t2.date_received.apply(lambda s:len(s.split(':')))\n",
    "t2 = t2[t2.receive_number>1]\n",
    "t2['max_date_received'] = t2.date_received.apply(lambda s:max([int(d) for d in s.split(':')]))\n",
    "t2['min_date_received'] = t2.date_received.apply(lambda s:min([int(d) for d in s.split(':')]))\n",
    "t2 = t2[['user_id','coupon_id','max_date_received','min_date_received']]\n",
    "\n",
    "t3 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t3 = pd.merge(t3,t2,on=['user_id','coupon_id'],how='left')\n",
    "t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received - t3.date_received\n",
    "t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received - t3.min_date_received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_firstlastone(x):\n",
    "    if x==0:\n",
    "        return 1\n",
    "    elif x>0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1 #those only receive once\n",
    "        \n",
    "t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "t3 = t3[['user_id','coupon_id','date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "\n",
    "t4 = dataset3[['user_id','date_received']]\n",
    "t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t5 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "t5 = t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t6 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t6.date_received = t6.date_received.astype('str')\n",
    "t6 = t6.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t6.rename(columns={'date_received':'dates'},inplace=True)\n",
    "\n",
    "def get_day_gap_before(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "        \n",
    "def get_day_gap_after(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "    \n",
    "\n",
    "t7 = dataset3[['user_id','coupon_id','date_received']]\n",
    "t7 = pd.merge(t7,t6,on=['user_id','coupon_id'],how='left')\n",
    "t7['date_received_date'] = t7.date_received.astype('str') + '-' + t7.dates\n",
    "t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "t7 = t7[['user_id','coupon_id','date_received','day_gap_before','day_gap_after']]\n",
    "\n",
    "other_feature3 = pd.merge(t1,t,on='user_id')\n",
    "other_feature3 = pd.merge(other_feature3,t3,on=['user_id','coupon_id'])\n",
    "other_feature3 = pd.merge(other_feature3,t4,on=['user_id','date_received'])\n",
    "other_feature3 = pd.merge(other_feature3,t5,on=['user_id','coupon_id','date_received'])\n",
    "other_feature3 = pd.merge(other_feature3,t7,on=['user_id','coupon_id','date_received'])\n",
    "other_feature3.to_csv('data/other_feature3.csv',index=None)\n",
    "# print other_feature3.shape\n",
    "\n",
    "\n",
    "\n",
    "#for dataset2\n",
    "t = dataset2[['user_id']]\n",
    "t['this_month_user_receive_all_coupon_count'] = 1\n",
    "t = t.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t1 = dataset2[['user_id','coupon_id']]\n",
    "t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "t2 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t2.date_received = t2.date_received.astype('str')\n",
    "t2 = t2.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t2['receive_number'] = t2.date_received.apply(lambda s:len(s.split(':')))\n",
    "t2 = t2[t2.receive_number>1]\n",
    "t2['max_date_received'] = t2.date_received.apply(lambda s:max([int(d) for d in s.split(':')]))\n",
    "t2['min_date_received'] = t2.date_received.apply(lambda s:min([int(d) for d in s.split(':')]))\n",
    "t2 = t2[['user_id','coupon_id','max_date_received','min_date_received']]\n",
    "\n",
    "t3 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t3 = pd.merge(t3,t2,on=['user_id','coupon_id'],how='left')\n",
    "t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received - t3.date_received.astype('int')\n",
    "t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received.astype('int') - t3.min_date_received\n",
    "def is_firstlastone(x):\n",
    "    if x==0:\n",
    "        return 1\n",
    "    elif x>0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1 #those only receive once\n",
    "        \n",
    "t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "t3 = t3[['user_id','coupon_id','date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "\n",
    "t4 = dataset2[['user_id','date_received']]\n",
    "t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t5 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "t5 = t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t6 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t6.date_received = t6.date_received.astype('str')\n",
    "t6 = t6.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t6.rename(columns={'date_received':'dates'},inplace=True)\n",
    "\n",
    "def get_day_gap_before(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "        \n",
    "def get_day_gap_after(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "    \n",
    "\n",
    "t7 = dataset2[['user_id','coupon_id','date_received']]\n",
    "t7 = pd.merge(t7,t6,on=['user_id','coupon_id'],how='left')\n",
    "t7['date_received_date'] = t7.date_received.astype('str') + '-' + t7.dates\n",
    "t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "t7 = t7[['user_id','coupon_id','date_received','day_gap_before','day_gap_after']]\n",
    "\n",
    "other_feature2 = pd.merge(t1,t,on='user_id')\n",
    "other_feature2 = pd.merge(other_feature2,t3,on=['user_id','coupon_id'])\n",
    "other_feature2 = pd.merge(other_feature2,t4,on=['user_id','date_received'])\n",
    "other_feature2 = pd.merge(other_feature2,t5,on=['user_id','coupon_id','date_received'])\n",
    "other_feature2 = pd.merge(other_feature2,t7,on=['user_id','coupon_id','date_received'])\n",
    "other_feature2.to_csv('data/other_feature2.csv',index=None)\n",
    "# print other_feature2.shape\n",
    "\n",
    "\n",
    "\n",
    "#for dataset1\n",
    "t = dataset1[['user_id']]\n",
    "t['this_month_user_receive_all_coupon_count'] = 1\n",
    "t = t.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t1 = dataset1[['user_id','coupon_id']]\n",
    "t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "t2 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t2.date_received = t2.date_received.astype('str')\n",
    "t2 = t2.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t2['receive_number'] = t2.date_received.apply(lambda s:len(s.split(':')))\n",
    "t2 = t2[t2.receive_number>1]\n",
    "t2['max_date_received'] = t2.date_received.apply(lambda s:max([int(d) for d in s.split(':')]))\n",
    "t2['min_date_received'] = t2.date_received.apply(lambda s:min([int(d) for d in s.split(':')]))\n",
    "t2 = t2[['user_id','coupon_id','max_date_received','min_date_received']]\n",
    "\n",
    "t3 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t3 = pd.merge(t3,t2,on=['user_id','coupon_id'],how='left')\n",
    "t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received - t3.date_received.astype('int')\n",
    "t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received.astype('int') - t3.min_date_received\n",
    "def is_firstlastone(x):\n",
    "    if x==0:\n",
    "        return 1\n",
    "    elif x>0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1 #those only receive once\n",
    "        \n",
    "t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "t3 = t3[['user_id','coupon_id','date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "\n",
    "t4 = dataset1[['user_id','date_received']]\n",
    "t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t5 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "t5 = t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "t6 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t6.date_received = t6.date_received.astype('str')\n",
    "t6 = t6.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t6.rename(columns={'date_received':'dates'},inplace=True)\n",
    "\n",
    "def get_day_gap_before(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "        \n",
    "def get_day_gap_after(s):\n",
    "    date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "    \n",
    "\n",
    "t7 = dataset1[['user_id','coupon_id','date_received']]\n",
    "t7 = pd.merge(t7,t6,on=['user_id','coupon_id'],how='left')\n",
    "t7['date_received_date'] = t7.date_received.astype('str') + '-' + t7.dates\n",
    "t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "t7 = t7[['user_id','coupon_id','date_received','day_gap_before','day_gap_after']]\n",
    "\n",
    "other_feature1 = pd.merge(t1,t,on='user_id')\n",
    "other_feature1 = pd.merge(other_feature1,t3,on=['user_id','coupon_id'])\n",
    "other_feature1 = pd.merge(other_feature1,t4,on=['user_id','date_received'])\n",
    "other_feature1 = pd.merge(other_feature1,t5,on=['user_id','coupon_id','date_received'])\n",
    "other_feature1 = pd.merge(other_feature1,t7,on=['user_id','coupon_id','date_received'])\n",
    "other_feature1.to_csv('data/other_feature1.csv',index=None)\n",
    "# print other_feature1.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############# coupon related feature   #############\n",
    "\"\"\"\n",
    "2.coupon related: \n",
    "      discount_rate. discount_man. discount_jian. is_man_jian\n",
    "      day_of_week,day_of_month. (date_received)\n",
    "\"\"\"\n",
    "def calc_discount_rate(s):\n",
    "    s =str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return float(s[0])\n",
    "    else:\n",
    "        return 1.0-float(s[1])/float(s[0])\n",
    "\n",
    "def get_discount_man(s):\n",
    "    s =str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[0])\n",
    "        \n",
    "def get_discount_jian(s):\n",
    "    s =str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[1])\n",
    "\n",
    "def is_man_jian(s):\n",
    "    s =str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "#dataset3\n",
    "dataset3['day_of_week'] = dataset3.date_received.astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "dataset3['day_of_month'] = dataset3.date_received.astype('str').apply(lambda x:int(x[6:8]))\n",
    "dataset3['days_distance'] = dataset3.date_received.astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,6,30)).days)\n",
    "dataset3['discount_man'] = dataset3.discount_rate.apply(get_discount_man)\n",
    "dataset3['discount_jian'] = dataset3.discount_rate.apply(get_discount_jian)\n",
    "dataset3['is_man_jian'] = dataset3.discount_rate.apply(is_man_jian)\n",
    "dataset3['discount_rate'] = dataset3.discount_rate.apply(calc_discount_rate)\n",
    "d = dataset3[['coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "dataset3 = pd.merge(dataset3,d,on='coupon_id',how='left')\n",
    "dataset3.to_csv('data/coupon3_feature.csv',index=None)\n",
    "#dataset2\n",
    "dataset2['day_of_week'] = dataset2.date_received.astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "dataset2['day_of_month'] = dataset2.date_received.astype('str').apply(lambda x:int(x[6:8]))\n",
    "dataset2['days_distance'] = dataset2.date_received.astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,5,14)).days)\n",
    "dataset2['discount_man'] = dataset2.discount_rate.apply(get_discount_man)\n",
    "dataset2['discount_jian'] = dataset2.discount_rate.apply(get_discount_jian)\n",
    "dataset2['is_man_jian'] = dataset2.discount_rate.apply(is_man_jian)\n",
    "dataset2['discount_rate'] = dataset2.discount_rate.apply(calc_discount_rate)\n",
    "d = dataset2[['coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "dataset2 = pd.merge(dataset2,d,on='coupon_id',how='left')\n",
    "dataset2.to_csv('data/coupon2_feature.csv',index=None)\n",
    "#dataset1\n",
    "dataset1['day_of_week'] = dataset1.date_received.astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "dataset1['day_of_month'] = dataset1.date_received.astype('str').apply(lambda x:int(x[6:8]))\n",
    "dataset1['days_distance'] = dataset1.date_received.astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,4,13)).days)\n",
    "dataset1['discount_man'] = dataset1.discount_rate.apply(get_discount_man)\n",
    "dataset1['discount_jian'] = dataset1.discount_rate.apply(get_discount_jian)\n",
    "dataset1['is_man_jian'] = dataset1.discount_rate.apply(is_man_jian)\n",
    "dataset1['discount_rate'] = dataset1.discount_rate.apply(calc_discount_rate)\n",
    "d = dataset1[['coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "dataset1 = pd.merge(dataset1,d,on='coupon_id',how='left')\n",
    "dataset1.to_csv('data/coupon1_feature.csv',index=None)\n",
    "\n",
    "\n",
    "\n",
    "############# merchant related feature   #############\n",
    "\"\"\"\n",
    "1.merchant related: \n",
    "      total_sales. sales_use_coupon.  total_coupon\n",
    "      coupon_rate = sales_use_coupon/total_sales.  \n",
    "      transfer_rate = sales_use_coupon/total_coupon. \n",
    "      merchant_avg_distance,merchant_min_distance,merchant_max_distance of those use coupon\n",
    "\"\"\"\n",
    "\n",
    "#for dataset3\n",
    "merchant3 = feature3[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "t = merchant3[['merchant_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = merchant3[merchant3.date!='null'][['merchant_id']]\n",
    "t1['total_sales'] = 1\n",
    "t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t2 = merchant3[(merchant3.date!='null')&(merchant3.coupon_id!='null')][['merchant_id']]\n",
    "t2['sales_use_coupon'] = 1\n",
    "t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t3 = merchant3[merchant3.coupon_id!='null'][['merchant_id']]\n",
    "t3['total_coupon'] = 1\n",
    "t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t4 = merchant3[(merchant3.date!='null')&(merchant3.coupon_id!='null')][['merchant_id','distance']]\n",
    "t4.replace('null',-1,inplace=True)\n",
    "t4.distance = t4.distance.astype('int')\n",
    "t4.replace(-1,np.nan,inplace=True)\n",
    "t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "t5.rename(columns={'distance':'merchant_min_distance'},inplace=True)\n",
    "\n",
    "t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "t6.rename(columns={'distance':'merchant_max_distance'},inplace=True)\n",
    "\n",
    "t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "t7.rename(columns={'distance':'merchant_mean_distance'},inplace=True)\n",
    "\n",
    "t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "t8.rename(columns={'distance':'merchant_median_distance'},inplace=True)\n",
    "\n",
    "merchant3_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t2,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t3,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t5,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t6,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t7,on='merchant_id',how='left')\n",
    "merchant3_feature = pd.merge(merchant3_feature,t8,on='merchant_id',how='left')\n",
    "merchant3_feature.sales_use_coupon = merchant3_feature.sales_use_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant3_feature['merchant_coupon_transfer_rate'] = merchant3_feature.sales_use_coupon.astype('float') / merchant3_feature.total_coupon\n",
    "merchant3_feature['coupon_rate'] = merchant3_feature.sales_use_coupon.astype('float') / merchant3_feature.total_sales\n",
    "merchant3_feature.total_coupon = merchant3_feature.total_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant3_feature.to_csv('data/merchant3_feature.csv',index=None)\n",
    "\n",
    "\n",
    "#for dataset2\n",
    "merchant2 = feature2[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "t = merchant2[['merchant_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = merchant2[merchant2.date!='null'][['merchant_id']]\n",
    "t1['total_sales'] = 1\n",
    "t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t2 = merchant2[(merchant2.date!='null')&(merchant2.coupon_id!='null')][['merchant_id']]\n",
    "t2['sales_use_coupon'] = 1\n",
    "t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t3 = merchant2[merchant2.coupon_id!='null'][['merchant_id']]\n",
    "t3['total_coupon'] = 1\n",
    "t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t4 = merchant2[(merchant2.date!='null')&(merchant2.coupon_id!='null')][['merchant_id','distance']]\n",
    "t4.replace('null',-1,inplace=True)\n",
    "t4.distance = t4.distance.astype('int')\n",
    "t4.replace(-1,np.nan,inplace=True)\n",
    "t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "t5.rename(columns={'distance':'merchant_min_distance'},inplace=True)\n",
    "\n",
    "t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "t6.rename(columns={'distance':'merchant_max_distance'},inplace=True)\n",
    "\n",
    "t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "t7.rename(columns={'distance':'merchant_mean_distance'},inplace=True)\n",
    "\n",
    "t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "t8.rename(columns={'distance':'merchant_median_distance'},inplace=True)\n",
    "\n",
    "merchant2_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t2,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t3,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t5,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t6,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t7,on='merchant_id',how='left')\n",
    "merchant2_feature = pd.merge(merchant2_feature,t8,on='merchant_id',how='left')\n",
    "merchant2_feature.sales_use_coupon = merchant2_feature.sales_use_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant2_feature['merchant_coupon_transfer_rate'] = merchant2_feature.sales_use_coupon.astype('float') / merchant2_feature.total_coupon\n",
    "merchant2_feature['coupon_rate'] = merchant2_feature.sales_use_coupon.astype('float') / merchant2_feature.total_sales\n",
    "merchant2_feature.total_coupon = merchant2_feature.total_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant2_feature.to_csv('data/merchant2_feature.csv',index=None)\n",
    "\n",
    "#for dataset1\n",
    "merchant1 = feature1[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "t = merchant1[['merchant_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = merchant1[merchant1.date!='null'][['merchant_id']]\n",
    "t1['total_sales'] = 1\n",
    "t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t2 = merchant1[(merchant1.date!='null')&(merchant1.coupon_id!='null')][['merchant_id']]\n",
    "t2['sales_use_coupon'] = 1\n",
    "t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t3 = merchant1[merchant1.coupon_id!='null'][['merchant_id']]\n",
    "t3['total_coupon'] = 1\n",
    "t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "t4 = merchant1[(merchant1.date!='null')&(merchant1.coupon_id!='null')][['merchant_id','distance']]\n",
    "t4.replace('null',-1,inplace=True)\n",
    "t4.distance = t4.distance.astype('int')\n",
    "t4.replace(-1,np.nan,inplace=True)\n",
    "t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "t5.rename(columns={'distance':'merchant_min_distance'},inplace=True)\n",
    "\n",
    "t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "t6.rename(columns={'distance':'merchant_max_distance'},inplace=True)\n",
    "\n",
    "t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "t7.rename(columns={'distance':'merchant_mean_distance'},inplace=True)\n",
    "\n",
    "t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "t8.rename(columns={'distance':'merchant_median_distance'},inplace=True)\n",
    "\n",
    "\n",
    "merchant1_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t2,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t3,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t5,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t6,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t7,on='merchant_id',how='left')\n",
    "merchant1_feature = pd.merge(merchant1_feature,t8,on='merchant_id',how='left')\n",
    "merchant1_feature.sales_use_coupon = merchant1_feature.sales_use_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant1_feature['merchant_coupon_transfer_rate'] = merchant1_feature.sales_use_coupon.astype('float') / merchant1_feature.total_coupon\n",
    "merchant1_feature['coupon_rate'] = merchant1_feature.sales_use_coupon.astype('float') / merchant1_feature.total_sales\n",
    "merchant1_feature.total_coupon = merchant1_feature.total_coupon.replace(np.nan,0) #fillna with 0\n",
    "merchant1_feature.to_csv('data/merchant1_feature.csv',index=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############# user related feature   #############\n",
    "\"\"\"\n",
    "3.user related: \n",
    "      count_merchant. \n",
    "      user_avg_distance, user_min_distance,user_max_distance. \n",
    "      buy_use_coupon. buy_total. coupon_received.\n",
    "      buy_use_coupon/coupon_received. \n",
    "      buy_use_coupon/buy_total\n",
    "      user_date_datereceived_gap\n",
    "      \n",
    "\"\"\"\n",
    "\n",
    "def get_user_date_datereceived_gap(s):\n",
    "    s = s.split(':')\n",
    "    return (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8])) - date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days\n",
    "\n",
    "#for dataset3\n",
    "user3 = feature3[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "t = user3[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = user3[user3.date!='null'][['user_id','merchant_id']]\n",
    "t1.drop_duplicates(inplace=True)\n",
    "t1.merchant_id = 1\n",
    "t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "t2 = user3[(user3.date!='null')&(user3.coupon_id!='null')][['user_id','distance']]\n",
    "t2.replace('null',-1,inplace=True)\n",
    "t2.distance = t2.distance.astype('int')\n",
    "t2.replace(-1,np.nan,inplace=True)\n",
    "t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "t7 = user3[(user3.date!='null')&(user3.coupon_id!='null')][['user_id']]\n",
    "t7['buy_use_coupon'] = 1\n",
    "t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t8 = user3[user3.date!='null'][['user_id']]\n",
    "t8['buy_total'] = 1\n",
    "t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t9 = user3[user3.coupon_id!='null'][['user_id']]\n",
    "t9['coupon_received'] = 1\n",
    "t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t10 = user3[(user3.date_received!='null')&(user3.date!='null')][['user_id','date_received','date']]\n",
    "t10['user_date_datereceived_gap'] = t10.date + ':' + t10.date_received\n",
    "t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "\n",
    "user3_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t3,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t4,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t5,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t6,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t7,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t8,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t9,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t11,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t12,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t13,on='user_id',how='left')\n",
    "user3_feature.count_merchant = user3_feature.count_merchant.replace(np.nan,0)\n",
    "user3_feature.buy_use_coupon = user3_feature.buy_use_coupon.replace(np.nan,0)\n",
    "user3_feature['buy_use_coupon_rate'] = user3_feature.buy_use_coupon.astype('float') / user3_feature.buy_total.astype('float')\n",
    "user3_feature['user_coupon_transfer_rate'] = user3_feature.buy_use_coupon.astype('float') / user3_feature.coupon_received.astype('float')\n",
    "user3_feature.buy_total = user3_feature.buy_total.replace(np.nan,0)\n",
    "user3_feature.coupon_received = user3_feature.coupon_received.replace(np.nan,0)\n",
    "user3_feature.to_csv('data/user3_feature.csv',index=None)\n",
    "\n",
    "\n",
    "#for dataset2\n",
    "user2 = feature2[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "t = user2[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = user2[user2.date!='null'][['user_id','merchant_id']]\n",
    "t1.drop_duplicates(inplace=True)\n",
    "t1.merchant_id = 1\n",
    "t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "t2 = user2[(user2.date!='null')&(user2.coupon_id!='null')][['user_id','distance']]\n",
    "t2.replace('null',-1,inplace=True)\n",
    "t2.distance = t2.distance.astype('int')\n",
    "t2.replace(-1,np.nan,inplace=True)\n",
    "t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "t7 = user2[(user2.date!='null')&(user2.coupon_id!='null')][['user_id']]\n",
    "t7['buy_use_coupon'] = 1\n",
    "t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t8 = user2[user2.date!='null'][['user_id']]\n",
    "t8['buy_total'] = 1\n",
    "t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t9 = user2[user2.coupon_id!='null'][['user_id']]\n",
    "t9['coupon_received'] = 1\n",
    "t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t10 = user2[(user2.date_received!='null')&(user2.date!='null')][['user_id','date_received','date']]\n",
    "t10['user_date_datereceived_gap'] = t10.date + ':' + t10.date_received\n",
    "t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "user2_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t3,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t4,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t5,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t6,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t7,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t8,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t9,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t11,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t12,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t13,on='user_id',how='left')\n",
    "user2_feature.count_merchant = user2_feature.count_merchant.replace(np.nan,0)\n",
    "user2_feature.buy_use_coupon = user2_feature.buy_use_coupon.replace(np.nan,0)\n",
    "user2_feature['buy_use_coupon_rate'] = user2_feature.buy_use_coupon.astype('float') / user2_feature.buy_total.astype('float')\n",
    "user2_feature['user_coupon_transfer_rate'] = user2_feature.buy_use_coupon.astype('float') / user2_feature.coupon_received.astype('float')\n",
    "user2_feature.buy_total = user2_feature.buy_total.replace(np.nan,0)\n",
    "user2_feature.coupon_received = user2_feature.coupon_received.replace(np.nan,0)\n",
    "user2_feature.to_csv('data/user2_feature.csv',index=None)\n",
    "\n",
    "\n",
    "#for dataset1\n",
    "user1 = feature1[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "t = user1[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = user1[user1.date!='null'][['user_id','merchant_id']]\n",
    "t1.drop_duplicates(inplace=True)\n",
    "t1.merchant_id = 1\n",
    "t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "t2 = user1[(user1.date!='null')&(user1.coupon_id!='null')][['user_id','distance']]\n",
    "t2.replace('null',-1,inplace=True)\n",
    "t2.distance = t2.distance.astype('int')\n",
    "t2.replace(-1,np.nan,inplace=True)\n",
    "t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "t7 = user1[(user1.date!='null')&(user1.coupon_id!='null')][['user_id']]\n",
    "t7['buy_use_coupon'] = 1\n",
    "t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t8 = user1[user1.date!='null'][['user_id']]\n",
    "t8['buy_total'] = 1\n",
    "t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t9 = user1[user1.coupon_id!='null'][['user_id']]\n",
    "t9['coupon_received'] = 1\n",
    "t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t10 = user1[(user1.date_received!='null')&(user1.date!='null')][['user_id','date_received','date']]\n",
    "t10['user_date_datereceived_gap'] = t10.date + ':' + t10.date_received\n",
    "t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "user1_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t3,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t4,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t5,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t6,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t7,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t8,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t9,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t11,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t12,on='user_id',how='left')\n",
    "user1_feature = pd.merge(user1_feature,t13,on='user_id',how='left')\n",
    "user1_feature.count_merchant = user1_feature.count_merchant.replace(np.nan,0)\n",
    "user1_feature.buy_use_coupon = user1_feature.buy_use_coupon.replace(np.nan,0)\n",
    "user1_feature['buy_use_coupon_rate'] = user1_feature.buy_use_coupon.astype('float') / user1_feature.buy_total.astype('float')\n",
    "user1_feature['user_coupon_transfer_rate'] = user1_feature.buy_use_coupon.astype('float') / user1_feature.coupon_received.astype('float')\n",
    "user1_feature.buy_total = user1_feature.buy_total.replace(np.nan,0)\n",
    "user1_feature.coupon_received = user1_feature.coupon_received.replace(np.nan,0)\n",
    "user1_feature.to_csv('data/user1_feature.csv',index=None)\n",
    "\n",
    "\n",
    "\n",
    "##################  user_merchant related feature #########################\n",
    "\n",
    "\"\"\"\n",
    "4.user_merchant:\n",
    "      times_user_buy_merchant_before. \n",
    "\"\"\"\n",
    "#for dataset3\n",
    "all_user_merchant = feature3[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature3[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature3[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "t2 = feature3[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "t3 = feature3[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "t4 = feature3[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant3 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3.user_merchant_buy_use_coupon = user_merchant3.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant3.user_merchant_buy_common = user_merchant3.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant3['user_merchant_coupon_transfer_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_received.astype('float')\n",
    "user_merchant3['user_merchant_coupon_buy_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "user_merchant3['user_merchant_rate'] = user_merchant3.user_merchant_buy_total.astype('float') / user_merchant3.user_merchant_any.astype('float')\n",
    "user_merchant3['user_merchant_common_buy_rate'] = user_merchant3.user_merchant_buy_common.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "user_merchant3.to_csv('data/user_merchant3.csv',index=None)\n",
    "\n",
    "#for dataset2\n",
    "all_user_merchant = feature2[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature2[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature2[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "t2 = feature2[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "t3 = feature2[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "t4 = feature2[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant2 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2.user_merchant_buy_use_coupon = user_merchant2.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant2.user_merchant_buy_common = user_merchant2.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant2['user_merchant_coupon_transfer_rate'] = user_merchant2.user_merchant_buy_use_coupon.astype('float') / user_merchant2.user_merchant_received.astype('float')\n",
    "user_merchant2['user_merchant_coupon_buy_rate'] = user_merchant2.user_merchant_buy_use_coupon.astype('float') / user_merchant2.user_merchant_buy_total.astype('float')\n",
    "user_merchant2['user_merchant_rate'] = user_merchant2.user_merchant_buy_total.astype('float') / user_merchant2.user_merchant_any.astype('float')\n",
    "user_merchant2['user_merchant_common_buy_rate'] = user_merchant2.user_merchant_buy_common.astype('float') / user_merchant2.user_merchant_buy_total.astype('float')\n",
    "user_merchant2.to_csv('data/user_merchant2.csv',index=None)\n",
    "\n",
    "#for dataset2\n",
    "all_user_merchant = feature1[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature1[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature1[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "t2 = feature1[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "t3 = feature1[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "t4 = feature1[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant1 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1.user_merchant_buy_use_coupon = user_merchant1.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant1.user_merchant_buy_common = user_merchant1.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant1['user_merchant_coupon_transfer_rate'] = user_merchant1.user_merchant_buy_use_coupon.astype('float') / user_merchant1.user_merchant_received.astype('float')\n",
    "user_merchant1['user_merchant_coupon_buy_rate'] = user_merchant1.user_merchant_buy_use_coupon.astype('float') / user_merchant1.user_merchant_buy_total.astype('float')\n",
    "user_merchant1['user_merchant_rate'] = user_merchant1.user_merchant_buy_total.astype('float') / user_merchant1.user_merchant_any.astype('float')\n",
    "user_merchant1['user_merchant_common_buy_rate'] = user_merchant1.user_merchant_buy_common.astype('float') / user_merchant1.user_merchant_buy_total.astype('float')\n",
    "user_merchant1.to_csv('data/user_merchant1.csv',index=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################  generate training and testing set ################\n",
    "def get_label(s):\n",
    "    s = s.split(':')\n",
    "    if s[0]=='null':\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8]))-date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days<=15:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "coupon3 = pd.read_csv('data/coupon3_feature.csv')\n",
    "merchant3 = pd.read_csv('data/merchant3_feature.csv')\n",
    "user3 = pd.read_csv('data/user3_feature.csv')\n",
    "user_merchant3 = pd.read_csv('data/user_merchant3.csv')\n",
    "other_feature3 = pd.read_csv('data/other_feature3.csv')\n",
    "dataset3 = pd.merge(coupon3,merchant3,on='merchant_id',how='left')\n",
    "dataset3 = pd.merge(dataset3,user3,on='user_id',how='left')\n",
    "dataset3 = pd.merge(dataset3,user_merchant3,on=['user_id','merchant_id'],how='left')\n",
    "dataset3 = pd.merge(dataset3,other_feature3,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "# print dataset3.shape\n",
    "\n",
    "dataset3.user_merchant_buy_total = dataset3.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset3.user_merchant_any = dataset3.user_merchant_any.replace(np.nan,0)\n",
    "dataset3.user_merchant_received = dataset3.user_merchant_received.replace(np.nan,0)\n",
    "dataset3['is_weekend'] = dataset3.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset3.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset3 = pd.concat([dataset3,weekday_dummies],axis=1)\n",
    "dataset3.drop(['merchant_id','day_of_week','coupon_count'],axis=1,inplace=True)\n",
    "dataset3 = dataset3.replace('null',np.nan)\n",
    "dataset3.to_csv('data/dataset3.csv',index=None)\n",
    "\n",
    "\n",
    "coupon2 = pd.read_csv('data/coupon2_feature.csv')\n",
    "merchant2 = pd.read_csv('data/merchant2_feature.csv')\n",
    "user2 = pd.read_csv('data/user2_feature.csv')\n",
    "user_merchant2 = pd.read_csv('data/user_merchant2.csv')\n",
    "other_feature2 = pd.read_csv('data/other_feature2.csv')\n",
    "dataset2 = pd.merge(coupon2,merchant2,on='merchant_id',how='left')\n",
    "dataset2 = pd.merge(dataset2,user2,on='user_id',how='left')\n",
    "dataset2 = pd.merge(dataset2,user_merchant2,on=['user_id','merchant_id'],how='left')\n",
    "dataset2 = pd.merge(dataset2,other_feature2,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset2.drop_duplicates(inplace=True)\n",
    "# print dataset2.shape\n",
    "\n",
    "dataset2.user_merchant_buy_total = dataset2.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset2.user_merchant_any = dataset2.user_merchant_any.replace(np.nan,0)\n",
    "dataset2.user_merchant_received = dataset2.user_merchant_received.replace(np.nan,0)\n",
    "dataset2['is_weekend'] = dataset2.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset2.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset2 = pd.concat([dataset2,weekday_dummies],axis=1)\n",
    "dataset2['label'] = dataset2.date.astype('str') + ':' +  dataset2.date_received.astype('str')\n",
    "dataset2.label = dataset2.label.apply(get_label)\n",
    "dataset2.drop(['merchant_id','day_of_week','date','date_received','coupon_id','coupon_count'],axis=1,inplace=True)\n",
    "dataset2 = dataset2.replace('null',np.nan)\n",
    "dataset2.to_csv('data/dataset2.csv',index=None)\n",
    "\n",
    "\n",
    "coupon1 = pd.read_csv('data/coupon1_feature.csv')\n",
    "merchant1 = pd.read_csv('data/merchant1_feature.csv')\n",
    "user1 = pd.read_csv('data/user1_feature.csv')\n",
    "user_merchant1 = pd.read_csv('data/user_merchant1.csv')\n",
    "other_feature1 = pd.read_csv('data/other_feature1.csv')\n",
    "dataset1 = pd.merge(coupon1,merchant1,on='merchant_id',how='left')\n",
    "dataset1 = pd.merge(dataset1,user1,on='user_id',how='left')\n",
    "dataset1 = pd.merge(dataset1,user_merchant1,on=['user_id','merchant_id'],how='left')\n",
    "dataset1 = pd.merge(dataset1,other_feature1,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "# print dataset1.shape\n",
    "\n",
    "dataset1.user_merchant_buy_total = dataset1.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset1.user_merchant_any = dataset1.user_merchant_any.replace(np.nan,0)\n",
    "dataset1.user_merchant_received = dataset1.user_merchant_received.replace(np.nan,0)\n",
    "dataset1['is_weekend'] = dataset1.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset1.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset1 = pd.concat([dataset1,weekday_dummies],axis=1)\n",
    "dataset1['label'] = dataset1.date.astype('str') + ':' +  dataset1.date_received.astype('str')\n",
    "dataset1.label = dataset1.label.apply(get_label)\n",
    "dataset1.drop(['merchant_id','day_of_week','date','date_received','coupon_id','coupon_count'],axis=1,inplace=True)\n",
    "dataset1 = dataset1.replace('null',np.nan)\n",
    "# dataset1.to_csv('data/dataset1.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
